{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bl7KKAKnjEI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "7GbI4AK9nn7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/gdrive/MyDrive/denemekaps3.rar"
      ],
      "metadata": {
        "id": "dWkPUSUxnnzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "59XkKx3mnnwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from keras import initializers, layers\n",
        "from keras.layers import *\n",
        "\n",
        "\n",
        "class Length(layers.Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[:-1]\n",
        "\n",
        "\n",
        "class Mask(layers.Layer):\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if type(inputs) is list:\n",
        "            assert len(inputs) == 2\n",
        "            inputs, mask = inputs\n",
        "            mask = K.expand_dims(mask, -1)\n",
        "        else:\n",
        "            x = K.sqrt(K.sum(K.square(inputs), -1, True))\n",
        "            x = (x - K.max(x, 1, True)) / K.epsilon() + 1\n",
        "            mask = K.clip(x, 0, 1)\n",
        "\n",
        "        return K.batch_flatten(inputs * mask)\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if type(input_shape[0]) is tuple:\n",
        "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
        "        else:\n",
        "            return tuple([None, input_shape[1] * input_shape[2]])\n",
        "\n",
        "\n",
        "def squash(vectors, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
        "    return scale * vectors\n",
        "\n",
        "\n",
        "class CapsuleLayer(layers.Layer):\n",
        "    def __init__(self, num_capsule, dim_capsule, num_routing=3,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.num_routing = num_routing\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) >= 3, \"Giriş Tensorunun olması gereken boyutu shape=[None, input_num_capsule, input_dim_capsule]\"\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "\n",
        "        # Matris Dönüştürme\n",
        "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
        "                                        self.dim_capsule, self.input_dim_capsule],\n",
        "                                 initializer=self.kernel_initializer,\n",
        "                                 name='W')\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "      inputs_expand = tf.expand_dims(inputs, 1)\n",
        "      inputs_tiled  = tf.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
        "      inputs_tiled  = tf.expand_dims(inputs_tiled, 4)\n",
        "\n",
        "      inputs_hat = tf.map_fn(lambda x: tf.matmul(self.W, x), elems=inputs_tiled)\n",
        "\n",
        "      b = tf.zeros(shape=[tf.shape(inputs_hat)[0], self.num_capsule,\n",
        "                      self.input_num_capsule, 1, 1])\n",
        "\n",
        "      assert self.num_routing > 0, 'The routings should be > 0.'\n",
        "      for i in range(self.num_routing):\n",
        "\n",
        "          c = layers.Softmax(axis=1)(b)\n",
        "\n",
        "          outputs = tf.multiply(c, inputs_hat)\n",
        "          outputs = tf.reduce_sum(outputs, axis=2, keepdims=True)\n",
        "          outputs = squash(outputs, axis=-2)\n",
        "\n",
        "          if i < self.num_routing - 1:\n",
        "             outputs_tiled = tf.tile(outputs, [1, 1, self.input_num_capsule, 1, 1])\n",
        "             agreement = tf.matmul(inputs_hat, outputs_tiled, transpose_a=True)\n",
        "             b = tf.add(b, agreement)\n",
        "\n",
        "      outputs = tf.squeeze(outputs, [2, 4])\n",
        "      return outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
        "\n",
        "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "#    inputTensor=Input(inputs)\n",
        "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
        "                           name='primarycap_conv2d')(inputs)\n",
        "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
        "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5abKGaMmnntu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import csv\n",
        "import math\n",
        "import pandas\n",
        "\n",
        "def plot_log(filename, show=True):\n",
        "\n",
        "    data = pandas.read_csv(filename)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,6))\n",
        "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
        "    fig.add_subplot(211)\n",
        "    for key in data.keys():\n",
        "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training loss')\n",
        "\n",
        "    fig.add_subplot(212)\n",
        "    for key in data.keys():\n",
        "        if key.find('acc') >= 0:  # acc\n",
        "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
        "    plt.legend()\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    # fig.savefig('result/log.png')\n",
        "    if show:\n",
        "        plt.show()\n",
        "        plt.savefig('acc_vs_epochs.png')\n",
        "\n",
        "\n",
        "def combine_images(generated_images, height=None, width=None):\n",
        "    num = generated_images.shape[0]\n",
        "    if width is None and height is None:\n",
        "        width = int(math.sqrt(num))\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif width is not None and height is None:  # height not given\n",
        "        height = int(math.ceil(float(num)/width))\n",
        "    elif height is not None and width is None:  # width not given\n",
        "        width = int(math.ceil(float(num)/height))\n",
        "\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height*shape[0], width*shape[1]),\n",
        "                     dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index/width)\n",
        "        j = index % width\n",
        "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
        "            img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    plot_log('log.csv')\n"
      ],
      "metadata": {
        "id": "6RDxcnVPoRvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import *\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import splitfolders\n",
        "import pandas as pd\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.color import rgb2gray\n",
        "K.set_image_data_format('channels_last')\n",
        "from tensorflow.keras.layers import Input, Dense, Lambda\n",
        "y_pred=[]\n",
        "\n",
        "\n",
        "def margin_loss(y_true, y_pred):\n",
        "\n",
        "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
        "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
        "\n",
        "    return K.mean(K.sum(L, 1))\n"
      ],
      "metadata": {
        "id": "uoA4VVzcoXCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import layers, models, optimizers, callbacks\n",
        "def train_generator(x, y, batch_size, shift_fraction=0.):\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        width_shift_range=shift_fraction,\n",
        "        height_shift_range=shift_fraction\n",
        "    )\n",
        "\n",
        "    generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
        "\n",
        "    def gen():\n",
        "        while True:\n",
        "            x_batch, y_batch = next(generator)\n",
        "            yield [x_batch, y_batch], [y_batch, x_batch]\n",
        "\n",
        "    return gen"
      ],
      "metadata": {
        "id": "ocweWMAaofD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, args):\n",
        "    (x_train, y_train), (x_test, y_test) = data\n",
        "\n",
        "    # Model ağırlıkları için dosya adı\n",
        "    weight_path = \"{}_capsnet.weights.h5\".format('BEST')\n",
        "\n",
        "    log = callbacks.CSVLogger('log.csv')\n",
        "    tb = callbacks.TensorBoard(\n",
        "        log_dir='./tensorboard-logs',\n",
        "        histogram_freq=args.debug,\n",
        "        write_graph=True,\n",
        "        write_images=True\n",
        "    )\n",
        "    checkpoint = callbacks.ModelCheckpoint(\n",
        "        weight_path,\n",
        "        monitor='capsnet_accuracy',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "    lr_decay = callbacks.LearningRateScheduler(\n",
        "        schedule=lambda epoch: args.lr * (0.9 ** epoch)\n",
        "    )\n",
        "    lr = args.lr\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=optimizers.Adam(learning_rate=lr),\n",
        "        loss=[margin_loss, 'mse'],\n",
        "        loss_weights=[1., args.lam_recon],\n",
        "        metrics={'capsnet': 'accuracy'}\n",
        "    )\n",
        "    model.fit(\n",
        "            [x_train, y_train],\n",
        "            [y_train, x_train],\n",
        "            batch_size=args.batch_size,\n",
        "            epochs=args.epochs,\n",
        "            validation_data=[[x_test, y_test], [y_test, x_test]],\n",
        "            callbacks=[log, tb, checkpoint]\n",
        "        )\n",
        "\n",
        "    # Modeli kaydetme\n",
        "    model.save_weights('trained_model.weights.h5')\n",
        "    print(\"Eğitilmiş model 'trained_model.weights.h5' olarak kaydedildi.\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "jRagQdbtolOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Lambda\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def CapsNet(input_shape, n_class, num_routing):\n",
        "    x = layers.Input(shape=input_shape)\n",
        "\n",
        "    conv1 = layers.Conv2D(filters=256, kernel_size=5, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
        "\n",
        "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=5, strides=2, padding='valid')\n",
        "\n",
        "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, num_routing=num_routing, name='digitcaps')(primarycaps)\n",
        "\n",
        "    # KATMAN 4: Lambda Katmanı ile Normalizasyon\n",
        "    #normalized_output = Lambda(lambda x: K.l2_normalize(x, axis=-1), output_shape=(n_class, 16), name=\"normalize_caps\")(digitcaps)\n",
        "\n",
        "    out_caps = Length(name='capsnet')(digitcaps)\n",
        "\n",
        "    # Kodçözücü Ağ\n",
        "    y = layers.Input(shape=(n_class,))\n",
        "    masked_by_y = Mask()([digitcaps, y])\n",
        "    masked = Mask()(digitcaps)\n",
        "\n",
        "    decoder = models.Sequential(name='decoder')\n",
        "    decoder.add(layers.Dense(512, activation='relu', input_dim=16 * n_class))\n",
        "    decoder.add(layers.Dense(1024, activation='relu'))\n",
        "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
        "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
        "\n",
        "    # Eğitim ve Değerlendirme için Modeller\n",
        "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
        "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
        "\n",
        "    return train_model, eval_model\n"
      ],
      "metadata": {
        "id": "mXqmNZVVo3lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "def test(model, data):\n",
        "    x_test, y_test = data\n",
        "    y_pred, x_recon = model.predict(x_test, batch_size=2)\n",
        "\n",
        "    # Test Accuracy\n",
        "    accuracy = np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1)) / y_test.shape[0]\n",
        "    print('-'*50)\n",
        "    print(f'Test accuracy: {accuracy}')\n",
        "\n",
        "    # Precision, Recall, F1 Score\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    precision = precision_score(y_true_classes, y_pred_classes, average='binary')  # binary classification\n",
        "    recall = recall_score(y_true_classes, y_pred_classes, average='binary')  # binary classification\n",
        "    f1 = f1_score(y_true_classes, y_pred_classes, average='binary')  # binary classification\n",
        "\n",
        "    print(f'Precision: {precision}')\n",
        "    print(f'Recall: {recall}')\n",
        "    print(f'F1 Score: {f1}')\n",
        "\n",
        "    # Save and visualize reconstructed images\n",
        "    import matplotlib.pyplot as plt\n",
        "    from PIL import Image\n",
        "\n",
        "    img = combine_images(np.concatenate([x_test[:50], x_recon[:50]]))\n",
        "    image = img * 255\n",
        "    Image.fromarray(image.astype(np.uint8)).save(\"real_and_recon.png\")\n",
        "    print()\n",
        "    print('Reconstructed images are saved to ./real_and_recon.png')\n",
        "    print('-'*50)\n",
        "    plt.imshow(plt.imread(\"real_and_recon.png\"))\n",
        "    plt.show()\n",
        "\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "ouKGiRd0pE01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Hiperparametrelerin Ayarlanması\n",
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--batch_size', default=4, type=int)\n",
        "parser.add_argument('--epochs', default=50, type=int)\n",
        "parser.add_argument('--lam_recon', default=4.92, type=float)\n",
        "parser.add_argument('--num_routing', default=3, type=int)\n",
        "parser.add_argument('--shift_fraction', default=0.1, type=float)\n",
        "parser.add_argument('--debug', default=0, type=int)\n",
        "parser.add_argument('--save_dir', default='./result')\n",
        "parser.add_argument('--is_training', default=1, type=int)\n",
        "parser.add_argument('--weights', default=None)\n",
        "parser.add_argument('--lr', default=0.0001, type=float)\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "if not os.path.exists(args.save_dir):\n",
        "    os.makedirs(args.save_dir)\n",
        "\n",
        "yol = '/content/denemekaps/'\n",
        "path = yol\n",
        "data = []\n",
        "label = []\n",
        "Files = ['herniyok', 'resim2']\n",
        "label_val = 0\n",
        "\n",
        "for files in Files:\n",
        "    cpath = os.path.join(path, files)\n",
        "    for img in sorted(os.listdir(cpath)):\n",
        "        image_array = cv2.imread(os.path.join(cpath, img), cv2.IMREAD_COLOR)\n",
        "        image_array = cv2.resize(image_array, (320, 320))\n",
        "        image_array = np.uint8(image_array)\n",
        "        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
        "        data.append(image_array)\n",
        "        label.append(label_val)\n",
        "    label_val = 1\n",
        "\n",
        "data = np.asarray(data)\n",
        "label = np.asarray(label, dtype=np.uint8)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "def create_model():\n",
        "    model, eval_model = CapsNet(input_shape=x_train.shape[1:],\n",
        "                                n_class=len(np.unique(np.argmax(y_train, 1))),\n",
        "                                num_routing=args.num_routing)\n",
        "    return model, eval_model\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(data)):\n",
        "    print(f\"\\nStarting fold {fold + 1}...\")\n",
        "\n",
        "    x_train, x_test = data[train_index], data[val_index]\n",
        "    y_train, y_test = label[train_index], label[val_index]\n",
        "\n",
        "    x_train = x_train.reshape(-1, 320, 320, 1).astype('float32') / 255.\n",
        "    x_test = x_test.reshape(-1, 320, 320, 1).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "\n",
        "    model, eval_model = create_model()\n",
        "    model.summary()\n",
        "\n",
        "    callbacks_list = [\n",
        "        EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True),\n",
        "        ModelCheckpoint(os.path.join(args.save_dir, f\"best_model_fold{fold + 1}.keras\"),\n",
        "                        monitor='val_loss', save_best_only=True, verbose=1)\n",
        "    ]\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=args.lr),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "    train(model=model, data=((x_train, y_train),(x_val,y_val)), args=args)\n",
        "\n",
        "\n",
        "    print(f\"Testing on fold {fold + 1}...\")\n",
        "    model.load_weights(f\"trained_model.weights.h5\")\n",
        "    ypred=test(model=eval_model, data=(x_test, y_test))\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZI9v9k4pGFx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}