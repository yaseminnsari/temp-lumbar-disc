{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bl7KKAKnjEI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "7GbI4AK9nn7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/gdrive/MyDrive/denemekaps3.rar"
      ],
      "metadata": {
        "id": "dWkPUSUxnnzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import layers, models, optimizers\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import *\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import splitfolders\n",
        "import pandas as pd\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.color import rgb2gray\n",
        "def load_mri():\n",
        "    yol = '/content/denemekaps/'\n",
        "    path = yol\n",
        "    data = []\n",
        "    label = []\n",
        "    Files = ['herniyok', 'resim2']\n",
        "    label_val = 0\n",
        "\n",
        "    for files in Files:\n",
        "        cpath = os.path.join(path, files)\n",
        "        cpath = os.path.join(cpath)\n",
        "\n",
        "        for img in sorted(os.listdir(cpath)):\n",
        "\n",
        "          image_array = cv2.imread(os.path.join(cpath, img), cv2.IMREAD_COLOR)\n",
        "          image_array=cv2.resize(image_array,(320,320))\n",
        "          image_array=np.uint8(image_array)\n",
        "          data.append(image_array)\n",
        "          label.append(label_val)\n",
        "        label_val = 1\n",
        "\n",
        "    data=np.asarray(data)\n",
        "    label =np.asarray(label,dtype=np.uint8)\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.3, random_state=42)\n",
        "\n",
        "    x_train = x_train.reshape(-1, 320, 320,3 ).astype('float32') / 255.\n",
        "    x_test = x_test.reshape(-1, 320, 320,3 ).astype('float32') / 255.\n",
        "    y_train = to_categorical(y_train.astype('float32'))\n",
        "    y_test = to_categorical(y_test.astype('float32'))\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)"
      ],
      "metadata": {
        "id": "59XkKx3mnnwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    yol = '/content/denemekaps/'\n",
        "    path = yol\n",
        "    data = []\n",
        "    label = []\n",
        "    Files = ['herniyok', 'resim2']\n",
        "    label_val = 0\n",
        "\n",
        "    for files in Files:\n",
        "        cpath = os.path.join(path, files)\n",
        "        cpath = os.path.join(cpath)\n",
        "\n",
        "        for img in sorted(os.listdir(cpath)):\n",
        "\n",
        "          image_array = cv2.imread(os.path.join(cpath, img), cv2.IMREAD_COLOR)\n",
        "          image_array=cv2.resize(image_array,(320,320))\n",
        "          image_array=np.uint8(image_array)\n",
        "          data.append(image_array)\n",
        "          label.append(label_val)\n",
        "        label_val = 1\n",
        "\n",
        "    data=np.asarray(data)\n",
        "    label =np.asarray(label,dtype=np.uint8)\n",
        "\n",
        "    data = data.reshape(-1, 320, 320,3 ).astype('float32') / 255.\n",
        "    label = to_categorical(label.astype('float32'))\n",
        "\n",
        "    return data, label"
      ],
      "metadata": {
        "id": "5abKGaMmnntu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pdb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def gwo_optimize(X_train, y_train, X_test, y_test):\n",
        "    search_agents = 5\n",
        "    max_iter = 50\n",
        " #   pdb.set_trace()\n",
        "    # GWO Başlangıç Pozisyonları\n",
        "    positions = np.random.uniform(low=-1, high=1, size=(search_agents, X_train.shape[1]))\n",
        "\n",
        "    # GWO Ana Döngü\n",
        "    for iteration in range(max_iter):\n",
        "        # GWO Popülasyonunu Değerlendir\n",
        "        fitness = evaluate_fitness(positions, X_train, y_train, X_test, y_test)\n",
        "\n",
        "        # GWO Algoritması\n",
        "        alpha, beta, delta = get_alpha_beta_delta(positions, fitness)\n",
        "        a = 2 - 2 * iteration / max_iter  # Azalma katsayısı\n",
        "\n",
        "        # Güncelleme formülü\n",
        "        positions = (alpha + beta + delta) / 3 + a * (np.random.uniform(size=positions.shape) - 0.5)\n",
        "\n",
        "    # GWO Optimizasyon Sonuçları\n",
        "    best_position = positions[np.argmin(fitness)]\n",
        "    return best_position\n",
        "\n",
        "# GWO Fitness Fonksiyonu\n",
        "def evaluate_fitness(positions, X_train, y_train, X_test, y_test):\n",
        "    fitness = []\n",
        "    for pos in positions:\n",
        "        # Her bir pozisyon için GWO ile optimize edilen öznitelikleri kullan\n",
        "        optimized_features = X_train * pos\n",
        "\n",
        "        # MLP Sınıflandırıcı ile eğitim\n",
        "        clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=50)\n",
        "        try:\n",
        "            clf.fit(optimized_features, y_train.argmax(axis=1))\n",
        "        except Exception as e:\n",
        "            print(f\"Hata: {e}\")\n",
        "            return np.zeros(len(y_test))  # Hataya düşerse fitness değerini sıfır olarak döndür\n",
        "\n",
        "        # Test verileri üzerinde tahmin yap\n",
        "        predictions = clf.predict(X_test * pos)\n",
        "\n",
        "        acc = accuracy_score(y_test.argmax(axis=1), predictions)\n",
        "        fitness.append(acc)\n",
        "\n",
        "    return np.array(fitness)\n",
        "\n",
        "# GWO Algoritması için Alpha, Beta, Delta'nın belirlenmesi\n",
        "def get_alpha_beta_delta(positions, fitness):\n",
        "    sorted_indices = np.argsort(fitness)\n",
        "    alpha, beta, delta = positions[sorted_indices[:3]]\n",
        "    return alpha, beta, delta"
      ],
      "metadata": {
        "id": "6RDxcnVPoRvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "input_shape = (320, 320, 3)\n",
        "\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "resnet_model = ResNet50(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "\n",
        "x = resnet_model(input_layer)\n",
        "\n",
        "x = Flatten()(x)\n",
        "\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "\n",
        "output_layer = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "1XCXj9kryGYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.optimize import minimize\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.optimize import minimize\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "weight_path = \"{}_resnetortak.weights.h5\".format('BEST')\n",
        "\n",
        "epochs = 50\n",
        "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                                   patience=4,\n",
        "                                   verbose=1, mode='min', lr=0.001, cooldown=2, min_lr=0.0001)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    weight_path,\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='auto',\n",
        "    save_weights_only=True  # .h5 formatı için bu parametre gereklidir\n",
        ")\n",
        "\n",
        "callbacks_list = [checkpoint]\n",
        "history = model.fit(\n",
        "  X_train.astype(np.float32), y_train.astype(np.float32),\n",
        "  batch_size=4,\n",
        "  shuffle=False,\n",
        "  validation_data=(x_val.astype(np.float32), y_val.astype(np.float32)),\n",
        "  epochs=epochs,\n",
        "  callbacks=callbacks_list\n",
        ")\n"
      ],
      "metadata": {
        "id": "luBZzrVyyMjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "fc_output_model = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
        "model.save(weight_path)\n",
        "best_model = load_model(weight_path)\n",
        "\n",
        "input_example = X_train[0:1].astype(np.float32)\n",
        "\n",
        "best_model.layers[-2].output.shape\n",
        "fully_connected_outputs = model.layers[-2].output\n",
        "data,label=load_data()\n",
        "X_train_fc_output = fc_output_model.predict(X_train)\n",
        "data_fc_output = fc_output_model.predict(data)\n",
        "X_val_fc_output = fc_output_model.predict(x_val)\n",
        "X_test_fc_output = fc_output_model.predict(X_test)\n",
        "print(\"fully_connected_outputs etiketleri boyutu:\", fully_connected_outputs.shape)\n",
        "print(\"X_train_fc_output etiketleri boyutu:\", X_train_fc_output.shape)\n",
        "print(\"X_val_fc_output etiketleri boyutu:\", X_val_fc_output.shape)\n",
        "print(\"X_test_fc_output etiketleri boyutu:\", X_test_fc_output.shape)\n",
        "print(\"data_fc_output etiketleri boyutu:\", data_fc_output.shape)"
      ],
      "metadata": {
        "id": "wy9R826hyRW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Eğitim ve doğrulama kayıpları\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Eğitim ve doğrulama doğrulukları\n",
        "train_acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "# Epoch sayısı\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Kayıp Eğrisi\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_loss, 'b', label='Eğitim Kaybı')\n",
        "plt.plot(epochs, val_loss, 'r', label='Doğrulama Kaybı')\n",
        "plt.title('Eğitim ve Doğrulama Kayıpları')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Kayıp')\n",
        "plt.legend()\n",
        "\n",
        "# Doğruluk Eğrisi\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_acc, 'b', label='Eğitim Doğruluğu')\n",
        "plt.plot(epochs, val_acc, 'r', label='Doğrulama Doğruluğu')\n",
        "plt.title('Eğitim ve Doğrulama Doğrulukları')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Doğruluk')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l1vn1coUyZXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizasyon İşlemi\n",
        "best_deger = gwo_optimize(X_train_fc_output, y_train, X_val_fc_output, y_val)\n",
        "print(\"Optimize Edilen:\", best_deger.shape)"
      ],
      "metadata": {
        "id": "vs3ofQhPyabi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
        "\n",
        "fold_accuracies = []\n",
        "train_accuracies = []\n",
        "loss_curves = []\n",
        "val_loss_curves = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(data_fc_output)):\n",
        "    data_fold, X_val_fold = data_fc_output[train_index], data_fc_output[val_index]\n",
        "    y_train_fold, y_val_fold = label[train_index], label[val_index]\n",
        "\n",
        "    mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=50, warm_start=True)\n",
        "\n",
        "    mlp_model.fit(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "\n",
        "    train_accuracy = mlp_model.score(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    val_predictions = mlp_model.predict(X_val_fold * best_deger)\n",
        "    val_accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "    loss_curves.append(mlp_model.loss_curve_)\n",
        "\n",
        "    print(f\"Fold Accuracy: {val_accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val_fold.argmax(axis=1), val_predictions, target_names=['noherni', 'herni']))\n",
        "\n",
        "    accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    precision = precision_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    cm = confusion_matrix(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['noherni', 'herni'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f\"Fold Confusion Matrix {fold+1}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "m-2UAqfyyehU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
        "\n",
        "fold_accuracies = []\n",
        "train_accuracies = []\n",
        "loss_curves = []\n",
        "val_loss_curves = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(data_fc_output)):\n",
        "\n",
        "    data_fold, X_val_fold = data_fc_output[train_index], data_fc_output[val_index]\n",
        "    y_train_fold, y_val_fold = label[train_index], label[val_index]\n",
        "\n",
        "    mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=50, warm_start=True,activation='identity')\n",
        "\n",
        "    mlp_model.fit(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "\n",
        "    train_accuracy = mlp_model.score(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    val_predictions = mlp_model.predict(X_val_fold * best_deger)\n",
        "    val_accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "    loss_curves.append(mlp_model.loss_curve_)\n",
        "\n",
        "    print(f\"Fold Accuracy: {val_accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val_fold.argmax(axis=1), val_predictions, target_names=['noherni', 'herni']))\n",
        "    accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    precision = precision_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    cm = confusion_matrix(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['noherni', 'herni'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f\"Fold Confusion Matrix {fold+1}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "QVBCPao40cBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
        "\n",
        "fold_accuracies = []\n",
        "train_accuracies = []\n",
        "loss_curves = []\n",
        "val_loss_curves = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(data_fc_output)):\n",
        "\n",
        "    data_fold, X_val_fold = data_fc_output[train_index], data_fc_output[val_index]\n",
        "    y_train_fold, y_val_fold = label[train_index], label[val_index]\n",
        "\n",
        "    mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=50, warm_start=True,activation='tanh')\n",
        "\n",
        "    mlp_model.fit(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "\n",
        "    train_accuracy = mlp_model.score(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    val_predictions = mlp_model.predict(X_val_fold * best_deger)\n",
        "    val_accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "    loss_curves.append(mlp_model.loss_curve_)\n",
        "\n",
        "    print(f\"Fold Accuracy: {val_accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val_fold.argmax(axis=1), val_predictions, target_names=['noherni', 'herni']))\n",
        "    accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    precision = precision_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "    cm = confusion_matrix(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['noherni', 'herni'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f\"Fold Confusion Matrix {fold+1}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "rt-qk8QRy1w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
        "\n",
        "fold_accuracies = []\n",
        "train_accuracies = []\n",
        "loss_curves = []\n",
        "val_loss_curves = []\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(data_fc_output)):\n",
        "\n",
        "    data_fold, X_val_fold = data_fc_output[train_index], data_fc_output[val_index]\n",
        "    y_train_fold, y_val_fold = label[train_index], label[val_index]\n",
        "\n",
        "    mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=50, warm_start=True,activation='logistic')\n",
        "\n",
        "    mlp_model.fit(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "\n",
        "    train_accuracy = mlp_model.score(data_fold * best_deger, y_train_fold.argmax(axis=1))\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    val_predictions = mlp_model.predict(X_val_fold * best_deger)\n",
        "    val_accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "    loss_curves.append(mlp_model.loss_curve_)\n",
        "\n",
        "    print(f\"Fold Accuracy: {val_accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_val_fold.argmax(axis=1), val_predictions, target_names=['noherni', 'herni']))\n",
        "\n",
        "    accuracy = accuracy_score(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    precision = precision_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold.argmax(axis=1), val_predictions, average='weighted')\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    cm = confusion_matrix(y_val_fold.argmax(axis=1), val_predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['noherni', 'herni'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f\"Fold Confusion Matrix {fold+1}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "print(f\"Average Validation Accuracy: {np.mean(fold_accuracies):.4f}\")\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "d-uD_N3zzEHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(data_fc_output)):\n",
        "    print(f\"Fold {fold + 1}...\")\n",
        "\n",
        "    data_fold, X_val_fold = data_fc_output[train_index], data_fc_output[val_index]\n",
        "    label_fold, y_val_fold = label[train_index], label[val_index]\n",
        "\n",
        "    svm_model = SVC(kernel='poly', C=1)\n",
        "\n",
        "    svm_model.fit(data_fold * best_deger, label_fold.argmax(axis=1))\n",
        "\n",
        "    train_accuracy = svm_model.score(data_fold * best_deger, label_fold.argmax(axis=1))\n",
        "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    svm_predictions = svm_model.predict(X_val_fold * best_deger)\n",
        "\n",
        "    accuracy = accuracy_score(y_val_fold.argmax(axis=1), svm_predictions)\n",
        "    precision = precision_score(y_val_fold.argmax(axis=1), svm_predictions, average='weighted')\n",
        "    recall = recall_score(y_val_fold.argmax(axis=1), svm_predictions, average='weighted')\n",
        "    f1 = f1_score(y_val_fold.argmax(axis=1), svm_predictions, average='weighted')\n",
        "\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    cm = confusion_matrix(y_val_fold.argmax(axis=1), svm_predictions)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['noherni', 'herni'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f\"Confusion Matrix - Fold {fold + 1}\")\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nCross-Validation Results:\")\n",
        "print(f\"Average Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Average Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Average Recall: {np.mean(recalls):.4f}\")\n",
        "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n"
      ],
      "metadata": {
        "id": "0cGPPdjKzPyf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}